<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="BDA Model Too Tough for Stan" />
<meta property="og:description" content="I taught a course on Bayesian data analysis, closely following the book by Andrew Gelman et al., but with the twist of using probabilistic programming, either Stan or Infergo, for all examples and exercises. However, it turned out that at least one important problem in the book is beyond the capabilities of Stan.
This case study is inspired by Section 7.6 in Bayesian Data Analysis, originally a paper published in 1983 by Ronald Rubin." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://dtolpin.github.io/posts/nypopu/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-29T18:00:54+03:00" />
<meta property="article:modified_time" content="2020-08-29T18:00:54+03:00" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="BDA Model Too Tough for Stan"/>
<meta name="twitter:description" content="I taught a course on Bayesian data analysis, closely following the book by Andrew Gelman et al., but with the twist of using probabilistic programming, either Stan or Infergo, for all examples and exercises. However, it turned out that at least one important problem in the book is beyond the capabilities of Stan.
This case study is inspired by Section 7.6 in Bayesian Data Analysis, originally a paper published in 1983 by Ronald Rubin."/>



    <link rel="canonical" href="http://dtolpin.github.io/posts/nypopu/">

    <title>
      
        BDA Model Too Tough for Stan | Offtopia — nothing personal
      
    </title>

    
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">

    <link href="http://dtolpin.github.io/css/style.css" rel="stylesheet">

    

    

    
  </head>
  <body>
    
      <header class="blog-header">
    <nav class="navbar navbar-expand-md navbar-light bg-light">
        <a class="navbar-brand" href="/">
            Offtopia — nothing personal
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
            aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-between" id="navbarNav">
            <ul class="navbar-nav">
                
                
                <li class="nav-item ">
                    
                        <a class="nav-link" href="/about/">About</a>
                    
                </li>
                
                <li class="nav-item ">
                    
                        <a class="nav-link" href="/academic/">Academic</a>
                    
                </li>
                
            </ul>
            
        </div>
    </nav>
</header>
    

    
    <div class="container">
      <div class="row">
        <div class="col-12 col-lg-8 blog-main">

          

<header>
    <h2 class="blog-post-title">
        <a class="text-dark" href="/posts/nypopu/">BDA Model Too Tough for Stan</a>
    </h2>
    
    <h3 class="blog-post-subtitle">Estimating the population of NY state from sample summaries</h3>
    
    


<div class="blog-post-date text-secondary">
    
        Aug 29, 2020
    
    
        by <span rel="author">David Tolpin</span>
    
</div>

    
    
    <hr>
</header>
<article class="blog-post">
    <p>I taught a course on Bayesian data analysis, closely following
<a href="http://www.stat.columbia.edu/~gelman/book/">the book by Andrew Gelman et
al.</a>, but with the
twist of using probabilistic programming, either
<a href="http://mc-stan.org/">Stan</a> or <a href="http://infergo.org/">Infergo</a>,
for all examples and exercises. However, it turned out that at
least one important problem in the book is beyond the
capabilities of Stan.</p>
<p>This case study is inspired by
Section 7.6 in <a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data
Analysis</a>,
originally a paper <a href="https://www.sciencedirect.com/science/article/pii/B978012121160850017X">published in 1983 by Ronald
Rubin</a>.
The original case study evaluated Bayesian inference on the
problem of estimation of total population of 804 municipalities
of New York state based on a sample of 100 municipalities. Two
samples were given, with different summary statistics, and
power-transformed normal model was fit to the data to make
predictions consistent among the samples. The authors of the
original case study apparently had access to the full data set
(populations of each of 100 municipalities in both samples).
However, only summary description of the samples appears in the
publication: the mean, the standard deviation, and
the quantiles:</p>
<table>
<thead>
<tr>
<th> </th>
<th>Population</th>
<th>Sample 1</th>
<th>Sample 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>total</strong></td>
<td>13,776,663</td>
<td>1,966,745</td>
<td>3,850,502</td>
</tr>
<tr>
<td><strong>mean</strong></td>
<td>17,135</td>
<td>19,667</td>
<td>38,505</td>
</tr>
<tr>
<td><strong>sd</strong></td>
<td>139,147</td>
<td>142,218</td>
<td>228,625</td>
</tr>
<tr>
<td><strong>lowest</strong></td>
<td>19</td>
<td>164</td>
<td>162</td>
</tr>
<tr>
<td><strong>5%</strong></td>
<td>336</td>
<td>308</td>
<td>315</td>
</tr>
<tr>
<td><strong>25%</strong></td>
<td>800</td>
<td>891</td>
<td>863</td>
</tr>
<tr>
<td><strong>median</strong></td>
<td>1,668</td>
<td>2,081</td>
<td>1,740</td>
</tr>
<tr>
<td><strong>75%</strong></td>
<td>5,050</td>
<td>6,049</td>
<td>5,239</td>
</tr>
<tr>
<td><strong>95%</strong></td>
<td>30,295</td>
<td>25,130</td>
<td>41,718</td>
</tr>
<tr>
<td><strong>highest</strong></td>
<td>2,627,319</td>
<td>1,424,815</td>
<td>1809578</td>
</tr>
</tbody>
</table>
<p>This is a common way to summarize a data sample, and
<a href="https://pandas.pydata.org/">Pandas</a>, a Python library for data
analysis, even has a built-in function which produces such
summary for data. Here, we show how such summary description can
be used to perform Bayesian inference, with the help of
<a href="https://arxiv.org/abs/2001.02656">stochastic conditioning</a>.</p>
<p>The sample summary can be divided into three parts:</p>
<ul>
<li>the sample size;</li>
<li>the mean and the standard deviation;</li>
<li>the quantiles.</li>
</ul>
<p>The sample size tells us how much information we have about the
distribution. The mean and the standard deviation describe the
distribution <em>parametrically</em> &mdash; if we knew the formula
of the probability density (parameterized by mean and standard
deviation), we could substitute these statistics into the
formula to fully specify the distribution. Finally, the
quantiles approximate the distribution shape
<em>non-parametrically</em> &mdash; we can sample from each quantile
proportionally to the probability mass of the quantile to
approximate samples from the distribution.</p>
<p>The original case study with comparing normal and log-normal
models, and finally fit a truncated three-parameter
power-transformed normal distribution to the data, which helped
to reconcile conclusions based on each of the samples while
producing results consistent with the total population. Here, we
use a model with log-normal sampling distribution and
normal-inverse-Gamma prior on the mean and variance. To complete
the model, we stochastically condition the model on the
piecewise-uniform distribution according to the quantiles:
$$z_{1\ldots\mathrm{n}} \leftarrow \mathrm{Quantiles}$$
$$m \sim \mathrm{Normal}(\mathrm{mean}, \frac {\mathrm{sd}} {\sqrt{\mathrm{n}}}),\quad s^2 \sim \mathrm{InvGamma}(\frac {\mathrm{n}} 2, \frac {\mathrm{n}} 2 \mathrm{sd}^2)$$
$$\sigma = \sqrt{\log \left(\frac {s^2} {m^2} + 1\right)},\quad\mu  = \log m - \frac {\sigma^2} 2$$
$$z_{1\ldots\mathrm{n}} \sim \mathrm{LogNormal}(\mu, \sigma)$$
By $z_{1\ldots\mathrm{n}}$ we denote $\mathrm{n}$ samples of
$z$ from the distribution defined by the quantiles. Here is the
model in Infergo:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">func</span> (m <span style="color:#666">*</span>Model) <span style="color:#06287e">Observe</span>(x []<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span> {
	mean <span style="color:#666">:=</span> x[<span style="color:#40a070">0</span>]
	vari <span style="color:#666">:=</span> math.<span style="color:#06287e">Exp</span>(x[<span style="color:#40a070">1</span>])
	logp <span style="color:#666">:=</span> x[<span style="color:#40a070">1</span>] <span style="color:#666">+</span>
		Normal.<span style="color:#06287e">Logp</span>(m.Mean, math.<span style="color:#06287e">Sqrt</span>(m.Vari<span style="color:#666">/</span>m.N), mean) <span style="color:#666">+</span>
		Gamma.<span style="color:#06287e">Logp</span>(m.N<span style="color:#666">/</span><span style="color:#40a070">2</span>, m.N<span style="color:#666">/</span><span style="color:#40a070">2</span><span style="color:#666">*</span>m.Vari, <span style="color:#40a070">1</span><span style="color:#666">/</span>vari)

	sigma <span style="color:#666">:=</span> math.<span style="color:#06287e">Sqrt</span>(math.<span style="color:#06287e">Log</span>(vari<span style="color:#666">/</span>(mean<span style="color:#666">*</span>mean) <span style="color:#666">+</span> <span style="color:#40a070">1</span>))
	mu <span style="color:#666">:=</span> math.<span style="color:#06287e">Log</span>(mean) <span style="color:#666">-</span> <span style="color:#40a070">0.5</span><span style="color:#666">*</span>sigma<span style="color:#666">*</span>sigma
	<span style="color:#007020;font-weight:bold">for</span> i <span style="color:#666">:=</span> <span style="color:#40a070">0.</span>; i <span style="color:#666">!=</span> m.N; i<span style="color:#666">++</span> {
		z <span style="color:#666">:=</span> <span style="color:#666">&lt;-</span>m.Z
		logp <span style="color:#666">+=</span> <span style="color:#666">-</span>math.<span style="color:#06287e">Log</span>(z) <span style="color:#666">+</span> Normal.<span style="color:#06287e">Logp</span>(mu, sigma, math.<span style="color:#06287e">Log</span>(z))
	}
	<span style="color:#007020;font-weight:bold">return</span> logp
}</code></pre></div>
<p>A straightforward way to sample from the quantiles is to sample a
quantile proportionally to the probability mass, and then sample
a value uniformly from the range of values in the quantile:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">func</span> <span style="color:#06287e">RandQuantile</span>(q [][<span style="color:#40a070">2</span>]<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span> {
	<span style="color:#007020;font-weight:bold">var</span> p, z <span style="color:#902000">float64</span>
	<span style="color:#007020;font-weight:bold">for</span> {
		p = rand.<span style="color:#06287e">ExpFloat64</span>()
		<span style="color:#007020;font-weight:bold">if</span> p &lt; <span style="color:#40a070">1</span> {
			<span style="color:#007020;font-weight:bold">break</span>
		}
	}
	<span style="color:#007020;font-weight:bold">for</span> i <span style="color:#666">:=</span> <span style="color:#40a070">1</span>; i <span style="color:#666">!=</span> <span style="color:#007020">len</span>(q); i<span style="color:#666">++</span> {
		<span style="color:#007020;font-weight:bold">if</span> q[i][<span style="color:#40a070">0</span>] <span style="color:#666">&gt;=</span> p {
			z = q[i<span style="color:#666">-</span><span style="color:#40a070">1</span>][<span style="color:#40a070">1</span>] <span style="color:#666">+</span> rand.<span style="color:#06287e">Float64</span>()<span style="color:#666">*</span>(q[i][<span style="color:#40a070">1</span>]<span style="color:#666">-</span>q[i<span style="color:#666">-</span><span style="color:#40a070">1</span>][<span style="color:#40a070">1</span>])
			<span style="color:#007020;font-weight:bold">break</span>
		}
	}
	<span style="color:#007020;font-weight:bold">return</span> z
}</code></pre></div>
<p>This is all we need to define the stochastically conditioned
probabilistic model in Infergo (the complete code and data are
<a href="https://bitbucket.org/dtolpin/stochastic-conditioning">on BitBucket</a>).
We fit the model using sgHMC. The posterior predictive
distributions from both samples are quite similar and consistent
with the summary of the total population:</p>
<table>
<thead>
<tr>
<th> </th>
<th>Sample 1</th>
<th>Sample 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>mean</strong></td>
<td>18,646</td>
<td>23,655</td>
</tr>
<tr>
<td><strong>5%</strong></td>
<td>82</td>
<td>69</td>
</tr>
<tr>
<td><strong>median</strong></td>
<td>2,389</td>
<td>2,395</td>
</tr>
<tr>
<td><strong>95</strong></td>
<td>66,381</td>
<td>80,296</td>
</tr>
</tbody>
</table>
<p><img src="/images/nypopu/posteriors.svg" alt="Predictive posteriors"></p>
<p>The model can be improved  by replacing log-normal
with power-transformed normal distribution. However, the point of
this case study has been to show how combining parametric and
non-parametric summaries can be easily expressed with stochastic
conditioning. It is not clear to us how to express a
probabilistic program for this study otherwise, using
deterministic conditioning only.</p>


    

    


</article>



        </div>

        <aside class="col-12 col-lg-3 ml-auto blog-sidebar">
    
        


<section>
    <h4>Recent Posts</h4>
    <ol class="list-unstyled">
        
        <li>
            <a href="/posts/double-speed-replay/">Double Speed Replay</a>
        </li>
        
        <li>
            <a href="/posts/">Posts</a>
        </li>
        
        <li>
            <a href="/posts/stochastic-conditioning/">Stochastic Conditioning</a>
        </li>
        
        <li>
            <a href="/posts/nypopu/">BDA Model Too Tough for Stan</a>
        </li>
        
        <li>
            <a href="/posts/weighted-white/">There Are No Outliers</a>
        </li>
        
    </ol>
</section>

    
    
        <section>
    
        
    
        
    
</section>
    
</aside>

      </div>
    </div>
    

    
      






<footer class="blog-footer w-100">
    <nav class="navbar navbar-light bg-light">
        <p class="w-100 text-center">Hugo template made with ❤ by <a href="https://github.com/Xzya">Xzya</a>, inspired by <a href="https://github.com/alanorth/hugo-theme-bootstrap4-blog">hugo-theme-bootstrap4-blog</a></p>
        <p class="w-100 text-center"><a href="#">Back to top</a></p>
    </nav>
</footer>

    

    
    
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>

    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script>
    <script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
  </body>
</html>
