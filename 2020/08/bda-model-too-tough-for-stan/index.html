<!DOCTYPE html>
<html lang="en" >

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property="og:url" content="http://dtolpin.github.io/2020/08/bda-model-too-tough-for-stan/">
  <meta property="og:site_name" content="Offtopia — nothing personal">
  <meta property="og:title" content="BDA Model Too Tough for Stan">
  <meta property="og:description" content="I taught a course on Bayesian data analysis, closely following the book by Andrew Gelman et al., but with the twist of using probabilistic programming, either Stan or Infergo, for all examples and exercises. However, it turned out that at least one important problem in the book is beyond the capabilities of Stan.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2020-08-29T18:00:54+03:00">
    <meta property="article:modified_time" content="2020-08-29T18:00:54+03:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="BDA Model Too Tough for Stan">
  <meta name="twitter:description" content="I taught a course on Bayesian data analysis, closely following the book by Andrew Gelman et al., but with the twist of using probabilistic programming, either Stan or Infergo, for all examples and exercises. However, it turned out that at least one important problem in the book is beyond the capabilities of Stan.">
<meta name="generator" content="Hugo 0.152.2">


    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "BDA Model Too Tough for Stan",
  "url": "http://dtolpin.github.io/2020/08/bda-model-too-tough-for-stan/",
  "wordCount": "753",
  "datePublished": "2020-08-29T18:00:54+03:00",
  "dateModified": "2020-08-29T18:00:54+03:00",
  "author": {
    "@type": "Person",
    "name": "David Tolpin"
  }
}
</script>



    <link rel="canonical" href="http://dtolpin.github.io/2020/08/bda-model-too-tough-for-stan/">

    <title>BDA Model Too Tough for Stan | Offtopia — nothing personal</title>

    
    <!-- combined, minified CSS -->
    
    <link href="http://dtolpin.github.io/css/style.c6ba80bc50669557645abe05f86b73cc5af84408ed20f1551a267bc19ece8228.css" rel="stylesheet" integrity="sha256-xrqAvFBmlVdkWr4F&#43;GtzzFr4RAjtIPFVGiZ7wZ7Ogig=" crossorigin="anonymous">
    
    
    <link href="http://dtolpin.github.io/css/substyle.f6bbec6fb714a00539d34a74ab7edb3a54048cb7745882eea95ba078edf0803c.css" rel="stylesheet" integrity="sha256-9rvsb7cUoAU500p0q37bOlQEjLd0WILuqVugeO3wgDw=" crossorigin="anonymous">

    <!-- minified Font Awesome for SVG icons -->
    
    <script defer src="http://dtolpin.github.io/js/fontawesome.min.f5072c55a0721857184db93a50561d7dc13975b4de2e19db7f81eb5f3fa57270.js" integrity="sha256-9QcsVaByGFcYTbk6UFYdfcE5dbTeLhnbf4HrXz&#43;lcnA=" crossorigin="anonymous"></script>

    <!-- RSS 2.0 feed -->
    

    

  </head>

  <body>

    
    <div class="blog-masthead">
      <div class="container">
        <nav class="nav blog-nav">
          <a class="nav-link " href="http://dtolpin.github.io/">Home</a>
          
          <a class="nav-link" href="/about/" title="">About</a>
          
          
          <a class="nav-link" href="/academic/" title="">Academic</a>
          
        </nav>
      </div>
    </div>
    

    
    
    <header class="blog-header">
      <div class="container">
        <h1 class="blog-title" dir="auto"><a href="http://dtolpin.github.io/" rel="home">Offtopia — nothing personal</a></h1>
        
      </div>
    </header>
    
    

    
    <div class="container">
      <div class="row">
        <div class="col-sm-8 blog-main">

          


<article class="blog-post">
  <header>
    <h2 class="blog-post-title" dir="auto"><a href="http://dtolpin.github.io/2020/08/bda-model-too-tough-for-stan/">BDA Model Too Tough for Stan</a></h2>
    
    <h3 class="blog-post-subtitle">Estimating the population of NY state from sample summaries</h3>
    
    <p class="blog-post-meta">
<time datetime="2020-08-29T18:00:54+03:00">Sat Aug 29, 2020</time>
</p>
  </header>
  <p>I taught a course on Bayesian data analysis, closely following
<a href="http://www.stat.columbia.edu/~gelman/book/">the book by Andrew Gelman et
al.</a>, but with the
twist of using probabilistic programming, either
<a href="http://mc-stan.org/">Stan</a> or <a href="http://infergo.org/">Infergo</a>,
for all examples and exercises. However, it turned out that at
least one important problem in the book is beyond the
capabilities of Stan.</p>
<p>This case study is inspired by
Section 7.6 in <a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data
Analysis</a>,
originally a paper <a href="https://www.sciencedirect.com/science/article/pii/B978012121160850017X">published in 1983 by Ronald
Rubin</a>.
The original case study evaluated Bayesian inference on the
problem of estimation of total population of 804 municipalities
of New York state based on a sample of 100 municipalities. Two
samples were given, with different summary statistics, and
power-transformed normal model was fit to the data to make
predictions consistent among the samples. The authors of the
original case study apparently had access to the full data set
(populations of each of 100 municipalities in both samples).
However, only summary description of the samples appears in the
publication: the mean, the standard deviation, and
the quantiles:</p>
<table>
  <thead>
      <tr>
          <th> </th>
          <th>Population</th>
          <th>Sample 1</th>
          <th>Sample 2</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>total</strong></td>
          <td>13,776,663</td>
          <td>1,966,745</td>
          <td>3,850,502</td>
      </tr>
      <tr>
          <td><strong>mean</strong></td>
          <td>17,135</td>
          <td>19,667</td>
          <td>38,505</td>
      </tr>
      <tr>
          <td><strong>sd</strong></td>
          <td>139,147</td>
          <td>142,218</td>
          <td>228,625</td>
      </tr>
      <tr>
          <td><strong>lowest</strong></td>
          <td>19</td>
          <td>164</td>
          <td>162</td>
      </tr>
      <tr>
          <td><strong>5%</strong></td>
          <td>336</td>
          <td>308</td>
          <td>315</td>
      </tr>
      <tr>
          <td><strong>25%</strong></td>
          <td>800</td>
          <td>891</td>
          <td>863</td>
      </tr>
      <tr>
          <td><strong>median</strong></td>
          <td>1,668</td>
          <td>2,081</td>
          <td>1,740</td>
      </tr>
      <tr>
          <td><strong>75%</strong></td>
          <td>5,050</td>
          <td>6,049</td>
          <td>5,239</td>
      </tr>
      <tr>
          <td><strong>95%</strong></td>
          <td>30,295</td>
          <td>25,130</td>
          <td>41,718</td>
      </tr>
      <tr>
          <td><strong>highest</strong></td>
          <td>2,627,319</td>
          <td>1,424,815</td>
          <td>1809578</td>
      </tr>
  </tbody>
</table>
<p>This is a common way to summarize a data sample, and
<a href="https://pandas.pydata.org/">Pandas</a>, a Python library for data
analysis, even has a built-in function which produces such
summary for data. Here, we show how such summary description can
be used to perform Bayesian inference, with the help of
<a href="https://arxiv.org/abs/2001.02656">stochastic conditioning</a>.</p>
<p>The sample summary can be divided into three parts:</p>
<ul>
<li>the sample size;</li>
<li>the mean and the standard deviation;</li>
<li>the quantiles.</li>
</ul>
<p>The sample size tells us how much information we have about the
distribution. The mean and the standard deviation describe the
distribution <em>parametrically</em> &mdash; if we knew the formula
of the probability density (parameterized by mean and standard
deviation), we could substitute these statistics into the
formula to fully specify the distribution. Finally, the
quantiles approximate the distribution shape
<em>non-parametrically</em> &mdash; we can sample from each quantile
proportionally to the probability mass of the quantile to
approximate samples from the distribution.</p>
<p>The original case study with comparing normal and log-normal
models, and finally fit a truncated three-parameter
power-transformed normal distribution to the data, which helped
to reconcile conclusions based on each of the samples while
producing results consistent with the total population. Here, we
use a model with log-normal sampling distribution and
normal-inverse-Gamma prior on the mean and variance. To complete
the model, we stochastically condition the model on the
piecewise-uniform distribution according to the quantiles:
$$z_{1\ldots\mathrm{n}} \leftarrow \mathrm{Quantiles}$$
$$m \sim \mathrm{Normal}(\mathrm{mean}, \frac {\mathrm{sd}} {\sqrt{\mathrm{n}}}),\quad s^2 \sim \mathrm{InvGamma}(\frac {\mathrm{n}} 2, \frac {\mathrm{n}} 2 \mathrm{sd}^2)$$
$$\sigma = \sqrt{\log \left(\frac {s^2} {m^2} + 1\right)},\quad\mu  = \log m - \frac {\sigma^2} 2$$
$$z_{1\ldots\mathrm{n}} \sim \mathrm{LogNormal}(\mu, \sigma)$$
By $z_{1\ldots\mathrm{n}}$ we denote $\mathrm{n}$ samples of
$z$ from the distribution defined by the quantiles. Here is the
model in Infergo:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">m</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">Model</span>) <span style="color:#a6e22e">Observe</span>(<span style="color:#a6e22e">x</span> []<span style="color:#66d9ef">float64</span>) <span style="color:#66d9ef">float64</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">mean</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">x</span>[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">vari</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Exp</span>(<span style="color:#a6e22e">x</span>[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">logp</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">x</span>[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">Normal</span>.<span style="color:#a6e22e">Logp</span>(<span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Mean</span>, <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>(<span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Vari</span><span style="color:#f92672">/</span><span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">N</span>), <span style="color:#a6e22e">mean</span>) <span style="color:#f92672">+</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">Gamma</span>.<span style="color:#a6e22e">Logp</span>(<span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">N</span><span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>, <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">N</span><span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Vari</span>, <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span><span style="color:#a6e22e">vari</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sigma</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#a6e22e">vari</span><span style="color:#f92672">/</span>(<span style="color:#a6e22e">mean</span><span style="color:#f92672">*</span><span style="color:#a6e22e">mean</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">mu</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#a6e22e">mean</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">0.5</span><span style="color:#f92672">*</span><span style="color:#a6e22e">sigma</span><span style="color:#f92672">*</span><span style="color:#a6e22e">sigma</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0.</span>; <span style="color:#a6e22e">i</span> <span style="color:#f92672">!=</span> <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">z</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Z</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">logp</span> <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#a6e22e">z</span>) <span style="color:#f92672">+</span> <span style="color:#a6e22e">Normal</span>.<span style="color:#a6e22e">Logp</span>(<span style="color:#a6e22e">mu</span>, <span style="color:#a6e22e">sigma</span>, <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#a6e22e">z</span>))
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">logp</span>
</span></span><span style="display:flex;"><span>}</span></span></code></pre></div>
<p>A straightforward way to sample from the quantiles is to sample a
quantile proportionally to the probability mass, and then sample
a value uniformly from the range of values in the quantile:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">RandQuantile</span>(<span style="color:#a6e22e">q</span> [][<span style="color:#ae81ff">2</span>]<span style="color:#66d9ef">float64</span>) <span style="color:#66d9ef">float64</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">p</span>, <span style="color:#a6e22e">z</span> <span style="color:#66d9ef">float64</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">p</span> = <span style="color:#a6e22e">rand</span>.<span style="color:#a6e22e">ExpFloat64</span>()
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">p</span> &lt; <span style="color:#ae81ff">1</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1</span>; <span style="color:#a6e22e">i</span> <span style="color:#f92672">!=</span> len(<span style="color:#a6e22e">q</span>); <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">q</span>[<span style="color:#a6e22e">i</span>][<span style="color:#ae81ff">0</span>] <span style="color:#f92672">&gt;=</span> <span style="color:#a6e22e">p</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">z</span> = <span style="color:#a6e22e">q</span>[<span style="color:#a6e22e">i</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>][<span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#a6e22e">rand</span>.<span style="color:#a6e22e">Float64</span>()<span style="color:#f92672">*</span>(<span style="color:#a6e22e">q</span>[<span style="color:#a6e22e">i</span>][<span style="color:#ae81ff">1</span>]<span style="color:#f92672">-</span><span style="color:#a6e22e">q</span>[<span style="color:#a6e22e">i</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>][<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">z</span>
</span></span><span style="display:flex;"><span>}</span></span></code></pre></div>
<p>This is all we need to define the stochastically conditioned
probabilistic model in Infergo (the complete code and data are
<a href="https://bitbucket.org/dtolpin/stochastic-conditioning">on BitBucket</a>).
We fit the model using sgHMC. The posterior predictive
distributions from both samples are quite similar and consistent
with the summary of the total population:</p>
<table>
  <thead>
      <tr>
          <th> </th>
          <th>Sample 1</th>
          <th>Sample 2</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>mean</strong></td>
          <td>18,646</td>
          <td>23,655</td>
      </tr>
      <tr>
          <td><strong>5%</strong></td>
          <td>82</td>
          <td>69</td>
      </tr>
      <tr>
          <td><strong>median</strong></td>
          <td>2,389</td>
          <td>2,395</td>
      </tr>
      <tr>
          <td><strong>95</strong></td>
          <td>66,381</td>
          <td>80,296</td>
      </tr>
  </tbody>
</table>
<p><img src="/images/nypopu/posteriors.svg" alt="Predictive posteriors"></p>
<p>The model can be improved  by replacing log-normal
with power-transformed normal distribution. However, the point of
this case study has been to show how combining parametric and
non-parametric summaries can be easily expressed with stochastic
conditioning. It is not clear to us how to express a
probabilistic program for this study otherwise, using
deterministic conditioning only.</p>


  

  
  <hr>
  <footer>

  
    <section>
    <h4>Share</h4>
    <nav class="nav sharing-icons">
      <a class="nav-item" href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2fdtolpin.github.io%2f2020%2f08%2fbda-model-too-tough-for-stan%2f" title="Share on Facebook"><span class="fab fa-facebook-f fa-2x" aria-hidden="true"></span></a>
      <a class="nav-item" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2fdtolpin.github.io%2f2020%2f08%2fbda-model-too-tough-for-stan%2f" title="Share on LinkedIn"><span class="fab fa-linkedin-in fa-2x" aria-hidden="true"></span></a>
      <a class="nav-item" href="https://twitter.com/intent/tweet?url=http%3a%2f%2fdtolpin.github.io%2f2020%2f08%2fbda-model-too-tough-for-stan%2f&amp;text=BDA%20Model%20Too%20Tough%20for%20Stan" title="Tweet this"><span class="fab fa-twitter fa-2x"></span></a>
    </nav>
  </section>

  

  
  </footer>
  

</article> 



        </div> <!-- /.blog-main -->

        <aside class="col-sm-3 ml-auto blog-sidebar">
  

  
        <section class="sidebar-module">
    <h4>Recent Posts</h4>
    <ol class="list-unstyled">


<li><a href="/2022/09/how-data-scientists-fail/">How Data Scientists Fail</a></li>

<li><a href="/2021/08/double-speed-replay/">Double Speed Replay</a></li>

<li><a href="/2021/08/how-to-train-your-program/">How To Train Your Program</a></li>

<li><a href="/2021/08/stochastic-conditioning/">Stochastic conditioning</a></li>

<li><a href="/2020/08/bda-model-too-tough-for-stan/">BDA Model Too Tough for Stan</a></li>

    </ol>
  </section>

  

  
  <section class="sidebar-module">
    <h4>Links</h4>
    <ol class="list-unstyled">
      
      <li><a href="https://infergo.org/">Infergo</a></li>
      
      <li><a href="https://offtopia.net/wp/">Old blog</a></li>
      
    </ol>
  </section>
  
</aside>


      </div> <!-- /.row -->
    </div> <!-- /.container -->
    

    
    <footer class="blog-footer">
      <p dir="auto">
      
      Blog template created by <a href="https://twitter.com/mdo">@mdo</a>, ported to Hugo by <a href='https://twitter.com/mralanorth'>@mralanorth</a>.
      
      </p>
      <p>
      <a href="#">Back to top</a>
      </p>
    </footer>
    

    
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script>

  </body>
</html>
